import json
import re
import os
from tqdm import tqdm
import ollama
import pandas as pd
from collections import Counter
from typing import List, Tuple, Dict, Any
from ollama import Client
client = Client(host="http://localhost:11434")

# -----------------------
# Configurable options
# -----------------------
MODEL_PARSER = "llama3.2:latest"          # model used to parse/assist (keep small)
MODEL_WARMUP = "llama3.2:latest"      # your warmup model (optional)
USE_MODEL_FOR_MANIPULATION = False    # If True, let model also produce manipulated output (voting)
SELF_CONSISTENCY_K = 5                # number of parse samples when using model-assisted parse
TEMPERATURE = 0.0                     # deterministic parsing
MAX_PREDICT = 80
INPUT_FILE = "test_10k.jsonl"
OUTPUT_FILE = "llama3_tocad_swap_eval.jsonl"
RESULTS_JSON = "llama3_tocad_swap_eval.json"

# --------------------------------------------------------------------
# Utilities: atomize, prompt builder, deterministic manipulators
# --------------------------------------------------------------------
def atomize_word(word: str) -> List[Tuple[int, str]]:
    """Return list of (1-based position, char) for the word."""
    return [(i + 1, ch) for i, ch in enumerate(list(word))]

def reconstruct_from_atoms(atoms: List[Tuple[int, str]]) -> str:
    """Join characters in order of positions to a string (no spaces)."""
    # Sort by position to be safe
    sorted_atoms = sorted(atoms, key=lambda x: x[0])
    return "".join(ch for _, ch in sorted_atoms)

def apply_swap_python(word: str, a: str, b: str) -> str:
    """Deterministic in-Python swap: swap all occurrences of a and b in word."""
    # Handle when a == b trivially
    if a == b:
        return word
    # Use placeholder approach to avoid collision (if a==b handled above)
    placeholder = "\u0000"
    # If placeholder occurs in word, pick another unlikely placeholder
    if placeholder in word:
        placeholder = "\u0001"
    s = word.replace(a, placeholder)
    s = s.replace(b, a)
    s = s.replace(placeholder, b)
    return s

def apply_insert_python(word: str, anchor: str, to_insert: str) -> str:
    """Insert to_insert after every anchor occurrence."""
    return word.replace(anchor, anchor + to_insert)

def apply_delete_python(word: str, target: str) -> str:
    """Delete all occurrences of target from word."""
    return word.replace(target, "")

# --------------------------------------------------------------------
# Prompt / parsing helpers (short, strict JSON output)
# --------------------------------------------------------------------
PARSER_PROMPT_TEMPLATE = """
You are a strict, precise text parser for character-edit instructions.

Input (atomized word): {atomized}
Instruction: {instruction}

Return ONLY a compact JSON with these fields:
{{
  "operation": "swap" | "insert" | "delete",
  "params": {{}},         # map of parameters (see examples)
  "atoms": [ [pos, "char"], ... ]   # list of character atoms (positions 1-based)
}}

Examples (do not include examples in your output):
- Swap 'a' and 'b' in word -> operation: "swap", params: {{"a":"a","b":"b"}}
- Insert 'x' after 'e' -> operation: "insert", params: {{"anchor":"e","insert":"x"}}
- Delete 'l' -> operation: "delete", params: {{"target":"l"}}

Return a single-line JSON only.
"""

def build_parse_prompt(atomized: List[Tuple[int, str]], instruction: str) -> str:
    atom_str = " ".join(f'({pos},{json.dumps(ch)})' for pos, ch in atomized)
    prompt = PARSER_PROMPT_TEMPLATE.format(atomized=atom_str, instruction=instruction)
    return prompt

def parse_model_json_response(response_text: str) -> Dict[str, Any]:
    """Extract the first JSON object from model response and parse it."""
    # Relaxed extraction: find the first {...} pair
    m = re.search(r'\{.*\}', response_text, flags=re.S)
    if not m:
        raise ValueError("No JSON object found in model response.")
    json_text = m.group(0)
    parsed = json.loads(json_text)
    # Normalize atoms if present: ensure list of [pos, char]
    if "atoms" in parsed:
        parsed["atoms"] = [[int(p), str(c)] for p, c in parsed["atoms"]]
    return parsed

# --------------------------------------------------------------------
# Model helpers: warmup and call with stable settings (ollama)
# --------------------------------------------------------------------
def warmup_models():
    """Optional: a tiny warmup call to ensure models load into memory (your previous pattern)."""
    try:
        _ = client.generate(
            model=MODEL_WARMUP,
            prompt="Ready?",
            options={"temperature": 0, "num_predict": 10}
        )
    except Exception:
        # ignore warmup errors; main calls will surface issues
        pass

def call_parser_with_retry(prompt: str, k: int = 1, temperature: float = TEMPERATURE) -> List[str]:
    """Call parser k times and return list of raw responses."""
    responses = []
    for i in range(k):
        res = client.generate(
            model=MODEL_PARSER,
            prompt=prompt,
            options={"temperature": temperature, "num_predict": MAX_PREDICT}
        )
        raw = res.get("response", "").strip() if isinstance(res, dict) else str(res).strip()
        responses.append(raw)
    return responses

# --------------------------------------------------------------------
# Voting and verification
# --------------------------------------------------------------------
def majority_vote_parses(raw_responses: List[str]) -> Dict[str, Any]:
    """Attempt to parse each raw response into JSON and vote on final parsed result.
       If parsing fails for all, raise ValueError.
    """
    parsed_list = []
    for r in raw_responses:
        try:
            p = parse_model_json_response(r)
            # Normalize to canonical tuple for voting
            op = p.get("operation")
            params = tuple(sorted(p.get("params", {}).items()))
            atoms = tuple((int(pos), str(ch)) for pos, ch in p.get("atoms", []))
            parsed_list.append((op, params, atoms, p))
        except Exception:
            continue

    if not parsed_list:
        raise ValueError("All parser attempts failed to produce valid JSON.")

    # Vote by (op, params, atoms)
    votes = Counter((op, params, atoms) for op, params, atoms, _ in parsed_list)
    winner_key, _ = votes.most_common(1)[0]
    # Retrieve the representative parsed object (first match)
    for op, params, atoms, original in parsed_list:
        if (op, params, atoms) == winner_key:
            return original

    # fallback
    return parsed_list[0][3]

def verify_result(expected_word: str, produced_word: str) -> bool:
    """Simple verification: characters count & length checks. Can be extended."""
    # For swap tasks, ensure same length and same char multiset
    return sorted(list(expected_word)) == sorted(list(produced_word))

# --------------------------------------------------------------------
# Main evaluation loop with ToCAD-style pipeline
# --------------------------------------------------------------------
def run_evaluation():
    # Load data (same filter as your original script)
    data = []
    with open(INPUT_FILE, "r", encoding="utf-8") as f:
        for line in f:
            line = line.strip()
            if not line:
                continue
            try:
                entry = json.loads(line)
                if entry.get("type", "").lower() == "swap":
                    data.append(entry)
            except json.JSONDecodeError:
                continue

    print(f"‚úÖ Loaded {len(data)} swap examples from {INPUT_FILE}")

    # Warmup
    warmup_models()
    print("üîÑ Models warmed up (if available).")

    results = []
    correct = 0
    total = len(data)

    for item in tqdm(data, desc="Evaluating swap responses"):
        # fields assumed: source (char a), target (char b), word, answer expected
        a = item.get("source")
        b = item.get("target")
        word = item.get("word")  # original word
        expected = item.get("answer")  # ground truth (expected transformed)

        # 1) Atomize
        atoms = atomize_word(word)

        # 2) Build short parser prompt
        instruction = f"Swap '{a}' and '{b}' in the given atomized word."
        prompt = build_parse_prompt(atoms, instruction)

        parsed = None
        model_used_parsed = None
        parse_failed = False

        # 3) Use model to parse (self-consistency if desired)
        try:
            raw_responses = call_parser_with_retry(prompt, k=SELF_CONSISTENCY_K if USE_MODEL_FOR_MANIPULATION else 1)
            if USE_MODEL_FOR_MANIPULATION:
                parsed = majority_vote_parses(raw_responses)
            else:
                # parse single response deterministically (k=1)
                parsed = parse_model_json_response(raw_responses[0])
            model_used_parsed = parsed
        except Exception as e:
            # parsing failed; fallback to constructing parsed result deterministically
            parse_failed = True
            # Build deterministic parse for swap
            parsed = {
                "operation": "swap",
                "params": {"a": a, "b": b},
                "atoms": [[pos, ch] for pos, ch in atoms]
            }

        # 4) Deterministic application of operation (primary)
        op = parsed.get("operation")
        params = parsed.get("params", {})
        parsed_atoms = parsed.get("atoms", [[pos, ch] for pos, ch in atoms])

        # reconstruct current word from parsed atoms (defensive)
        try:
            current_word = reconstruct_from_atoms([(int(pos), str(ch)) for pos, ch in parsed_atoms])
        except Exception:
            current_word = word

        # Apply operation deterministically in Python (this avoids hallucination)
        if op == "swap":
            a_param = params.get("a", a)
            b_param = params.get("b", b)
            produced = apply_swap_python(current_word, a_param, b_param)
        elif op == "insert":
            anchor = params.get("anchor")
            insert_ch = params.get("insert")
            produced = apply_insert_python(current_word, anchor, insert_ch)
        elif op == "delete":
            target = params.get("target")
            produced = apply_delete_python(current_word, target)
        else:
            # unknown op -> fallback to deterministic swap (safe)
            produced = apply_swap_python(current_word, a, b)

        # 5) Optional: if USE_MODEL_FOR_MANIPULATION True, request model to produce final and vote
        model_final = None
        if USE_MODEL_FOR_MANIPULATION:
            # Build small prompt instructing model to output final string only (JSON p_answer)
            examples_block = ""  # keep empty to avoid long prompts
            instruction_short = f"Swap '{a}' and '{b}' in the atomized word and return final string only in JSON: {{\"p_answer\":\"<word>\"}}"
            atom_str = " ".join(f'({pos},{json.dumps(ch)})' for pos, ch in atoms)
            final_prompt = f"Atomized: {atom_str}\nInstruction: {instruction_short}\nReturn single-line JSON only."
            try:
                raw_final_responses = call_parser_with_retry(final_prompt, k=SELF_CONSISTENCY_K)
                # parse p_answer from responses and majority vote
                p_answers = []
                for raw in raw_final_responses:
                    m = re.search(r'"p_answer"\s*:\s*"([^"]+)"', raw)
                    if m:
                        p_answers.append(m.group(1).strip())
                if p_answers:
                    most_common = Counter(p_answers).most_common(1)[0][0]
                    model_final = most_common
                else:
                    model_final = None
            except Exception:
                model_final = None

        # Decide final output: prefer deterministic produced; if model_final exists and matches verification, consider it
        final_output = produced
        if model_final:
            # If model_final equals deterministic produced, good. Otherwise pick deterministic (safer)
            if model_final == produced:
                final_output = produced
            else:
                # if model_final passes verification against expected (if expected available), we could prefer it.
                if expected and model_final == expected:
                    final_output = model_final
                else:
                    # keep deterministic (safer)
                    final_output = produced

        # 6) Post-processing: remove spaces (your earlier behavior) and standardize
        final_output_norm = final_output.replace(" ", "")

        # 7) Compare to expected
        is_correct = (final_output_norm == expected)
        if is_correct:
            correct += 1

        # Collect data for output
        results.append({
            "word": word,
            "a": a,
            "b": b,
            "expected": expected,
            "final_output": final_output_norm,
            "is_correct": is_correct,
            "parse_failed": parse_failed,
            "model_parse": model_used_parsed,
        })

    # Summary
    accuracy = (correct / total) * 100 if total > 0 else 0
    print(f"\n‚úÖ Swap Accuracy: {correct}/{total} = {accuracy:.2f}%")

    # Save results (jsonl + aggregated json)
    with open(OUTPUT_FILE, "w", encoding="utf-8") as outf:
        for r in results:
            outf.write(json.dumps(r, ensure_ascii=False) + "\n")

    df = pd.DataFrame(results)
    df.to_json(RESULTS_JSON, orient="records", indent=2, force_ascii=False)
    print(f"\nüìÅ Saved results to: {OUTPUT_FILE} and summary to {RESULTS_JSON}")

if __name__ == "_main_":
    run_evaluation()